{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Text Normalization\n",
    "\n",
    "This script reads an Excel file containing lyrics data, normalizes the text in the lyrics, and saves the modified data back to an Excel file.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Read the Excel file**: The pandas library is used to read the Excel file containing the lyrics data. The file path is specified in the code.\n",
    "\n",
    "2. **Normalize text**: A function `normalize_text` is defined to normalize the text in the lyrics. This function converts the text to lowercase, normalizes whitespace, and keeps only certain punctuation marks. It uses the `unicodedata` library to categorize characters.\n",
    "\n",
    "3. **Apply the normalization function**: The `normalize_text` function is applied to the 'Lyrics' column of the DataFrame. The normalized texts are stored in a new column 'NormalizedText'.\n",
    "\n",
    "4. **Save the modified DataFrame**: The modified DataFrame, which now includes the normalized text, is saved to an Excel file. The output file path is specified in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('../Chara-Based-Model/DataSets/Lyrics Training Data GPT Generated.xlsx', engine='openpyxl')\n",
    "\n",
    "# Normalize text\n",
    "def normalize_text(texts):\n",
    "    normalized_texts = []\n",
    "    keep_punctuation = {\"'\", \"-\", \"â€™\"}  # Add or remove characters as needed\n",
    "    for text in texts:\n",
    "        try:\n",
    "            text = str(text).lower()  # Convert to lowercase and ensure text is string\n",
    "            text = ' '.join(text.split())  # Normalize whitespace\n",
    "            # Iterate over each character in the text\n",
    "            # and include it in the output if it meets certain conditions\n",
    "            text = ''.join(\n",
    "                char for char in text \n",
    "                if unicodedata.category(char)[0] in ('L', 'N', 'Z')  # Check if the character is a letter, number, or space\n",
    "                or char in keep_punctuation  # Or if the character is in the custom set of punctuation marks to keep\n",
    "            )\n",
    "\n",
    "            normalized_texts.append(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text: {text} with error {e}\")\n",
    "            normalized_texts.append(text)  # Append original text or handle as needed\n",
    "    return normalized_texts\n",
    "\n",
    "\n",
    "# Normalize text\n",
    "normalized_texts = normalize_text(df['Lyrics'].astype(str))\n",
    "\n",
    "# Add the normalized text to the dataframe\n",
    "df['NormalizedText'] = normalized_texts\n",
    "\n",
    "# Save the modified DataFrame\n",
    "output_path = 'normalized_text.xlsx'  # Replace with a path that is not synced\n",
    "df.to_excel(output_path, engine='openpyxl', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing and Label Binarization in Python\n",
    "\n",
    "This script reads an Excel file containing normalized text data, processes the text, converts language labels into a binary matrix, and writes the processed data back to a new Excel file.\n",
    "\n",
    "## Libraries Used\n",
    "- pandas: For data manipulation and analysis.\n",
    "- sklearn.preprocessing: Provides a utility class MultiLabelBinarizer for transforming multiclass labels to binary labels.\n",
    "\n",
    "## Steps\n",
    "1. The required libraries are imported.\n",
    "2. The normalized Excel file is read into a pandas DataFrame.\n",
    "3. The 'Languages' column of the DataFrame is processed to convert the comma-separated string of languages into a list of languages.\n",
    "4. The MultiLabelBinarizer is initialized.\n",
    "5. The language labels are converted into a binary matrix.\n",
    "6. A new DataFrame is created for the binary matrix with appropriate column names.\n",
    "7. The original DataFrame is concatenated with the new binary matrix DataFrame.\n",
    "8. The resulting DataFrame is written to a new Excel file.\n",
    "\n",
    "Please ensure that the required libraries are installed in your Python environment before running this script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame saved to combined_normalized_text.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_excel(\"./normalized_text.xlsx\")  # Update the path to where you've stored the file\n",
    "\n",
    "# Step 2: Process the 'Languages' column to handle multiple labels\n",
    "# Split the string on commas to get a list of languages for each entry\n",
    "# Correctly process the 'Langauges' column to ensure it contains lists of languages without extra characters\n",
    "df['Langauges'] = df['Langauges'].apply(lambda x: [lang.strip() for lang in x.split(',') if lang.strip()])\n",
    "\n",
    "# Reinitialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Reconvert language labels into a binary matrix format\n",
    "binary_matrix = mlb.fit_transform(df['Langauges'])\n",
    "\n",
    "# Reconvert the binary matrix back into a DataFrame for easy viewing/manipulation\n",
    "binary_matrix_df_corrected = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
    "\n",
    "# Inspect the corrected DataFrame\n",
    "binary_matrix_df_corrected.head()\n",
    "\n",
    "\n",
    "# Merge the binary matrix with the original DataFrame\n",
    "df_combined = pd.concat([df, binary_matrix_df_corrected], axis=1)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file\n",
    "output_file_path = \"combined_normalized_text.xlsx\"  # Specify your desired output file path\n",
    "df_combined.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Combined DataFrame saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AR,EN,FR' 'DE,ES,KO' 'EN,HI,RU' 'EN,ES,PT' 'EN,FR,IT' 'EN,FR' 'AR,FR'\n",
      " 'EN,KO' 'ES,IT' 'EN,SW' 'DE,EN' 'AR,EN' 'EN,ES' 'EN,IS' 'ES,PT']\n"
     ]
    }
   ],
   "source": [
    "print(df['Langauges'].apply(lambda x: ','.join(sorted(x))).unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import unicodedata\n",
    "\n",
    "# Install the required libraries by running this in your Python environment:\n",
    "# pip install pandas openpyxl\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('/home/ramzidaher/OneDrive/Desktop/[02] University/Third Year/Individual Project/DataSets/Lyrics Training Data GPT Generated.xlsx', engine='openpyxl')\n",
    "\n",
    "# Assume the text is in a column named 'Text'\n",
    "texts = df['Lyrics'].tolist()\n",
    "\n",
    "# Normalize text\n",
    "def normalize_text(texts):\n",
    "    normalized_texts = []\n",
    "    for text in texts:\n",
    "        text = str(text).lower()  # Convert to lowercase and ensure text is string\n",
    "        text = ' '.join(text.split())  # Normalize whitespace\n",
    "        text = ''.join(char for char in text if unicodedata.category(char)[0] in ('L', 'N', 'P', 'Z'))  # Keep letters, numbers, punctuation, and separators\n",
    "        normalized_texts.append(text)\n",
    "    return normalized_texts\n",
    "\n",
    "normalized_texts = normalize_text(texts)\n",
    "\n",
    "# Assuming the column with text is named 'YourColumnName'\n",
    "texts = df['Lyrics'].astype(str).tolist()\n",
    "\n",
    "# Normalize text\n",
    "normalized_texts = normalize_text(texts)\n",
    "\n",
    "# Add the normalized text to the dataframe\n",
    "df['NormalizedText'] = normalized_texts\n",
    "\n",
    "# Save the dataframe with the normalized text to a new Excel file\n",
    "df.to_excel('normalized_text.xlsx', engine='openpyxl', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/python3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/ramzidaher/.local/lib/python3.10/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: packaging in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: setuptools in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (69.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (2.15.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (1.60.1)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ramzidaher/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ramzidaher/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ramzidaher/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ramzidaher/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ramzidaher/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ramzidaher/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ramzidaher/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ramzidaher/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ramzidaher/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ramzidaher/.local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "# Use this executable path to install TensorFlow\n",
    "!{sys.executable} -m pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-69.1.0-py3-none-any.whl (819 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.60.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting six>=1.12.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.28.0-py2.py3-none-any.whl (186 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, opt-einsum, ml-dtypes, h5py, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: libclang\n",
      "    Found existing installation: libclang 16.0.6\n",
      "    Uninstalling libclang-16.0.6:\n",
      "      Successfully uninstalled libclang-16.0.6\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.5.26\n",
      "    Uninstalling flatbuffers-23.5.26:\n",
      "      Successfully uninstalled flatbuffers-23.5.26\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.14.1\n",
      "    Uninstalling wrapt-1.14.1:\n",
      "      Successfully uninstalled wrapt-1.14.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.42.0\n",
      "    Uninstalling wheel-0.42.0:\n",
      "      Successfully uninstalled wheel-0.42.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.4.0\n",
      "    Uninstalling termcolor-2.4.0:\n",
      "      Successfully uninstalled termcolor-2.4.0\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.36.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.36.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.36.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.1.0\n",
      "    Uninstalling setuptools-69.1.0:\n",
      "      Successfully uninstalled setuptools-69.1.0\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.5.1\n",
      "    Uninstalling pyasn1-0.5.1:\n",
      "      Successfully uninstalled pyasn1-0.5.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.2\n",
      "    Uninstalling oauthlib-3.2.2:\n",
      "      Successfully uninstalled oauthlib-3.2.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.5\n",
      "    Uninstalling MarkupSafe-2.1.5:\n",
      "      Successfully uninstalled MarkupSafe-2.1.5\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.5.2\n",
      "    Uninstalling Markdown-3.5.2:\n",
      "      Successfully uninstalled Markdown-3.5.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.6\n",
      "    Uninstalling idna-3.6:\n",
      "      Successfully uninstalled idna-3.6\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.60.1\n",
      "    Uninstalling grpcio-1.60.1:\n",
      "      Successfully uninstalled grpcio-1.60.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.4\n",
      "    Uninstalling gast-0.5.4:\n",
      "      Successfully uninstalled gast-0.5.4\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.2.2\n",
      "    Uninstalling certifi-2024.2.2:\n",
      "      Successfully uninstalled certifi-2024.2.2\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.3.2\n",
      "    Uninstalling cachetools-5.3.2:\n",
      "      Successfully uninstalled cachetools-5.3.2\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 3.0.1\n",
      "    Uninstalling Werkzeug-3.0.1:\n",
      "      Successfully uninstalled Werkzeug-3.0.1\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1-modules 0.3.0\n",
      "    Uninstalling pyasn1-modules-0.3.0:\n",
      "      Successfully uninstalled pyasn1-modules-0.3.0\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.10.0\n",
      "    Uninstalling h5py-3.10.0:\n",
      "      Successfully uninstalled h5py-3.10.0\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: astunparse\n",
      "    Found existing installation: astunparse 1.6.3\n",
      "    Uninstalling astunparse-1.6.3:\n",
      "      Successfully uninstalled astunparse-1.6.3\n",
      "  Attempting uninstall: requests-oauthlib\n",
      "    Found existing installation: requests-oauthlib 1.3.1\n",
      "    Uninstalling requests-oauthlib-1.3.1:\n",
      "      Successfully uninstalled requests-oauthlib-1.3.1\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.28.0\n",
      "    Uninstalling google-auth-2.28.0:\n",
      "      Successfully uninstalled google-auth-2.28.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.2.0\n",
      "    Uninstalling google-auth-oauthlib-1.2.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.2\n",
      "    Uninstalling tensorboard-2.15.2:\n",
      "      Successfully uninstalled tensorboard-2.15.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0.post1\n",
      "    Uninstalling tensorflow-2.15.0.post1:\n",
      "      Successfully uninstalled tensorflow-2.15.0.post1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flask-sqlalchemy 3.1.1 requires sqlalchemy>=2.0.16, but you have sqlalchemy 1.4.50 which is incompatible.\n",
      "botocore 1.34.5 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 certifi-2024.2.2 charset-normalizer-3.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.28.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.1 h5py-3.10.0 idna-3.6 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.2 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 setuptools-69.1.0 six-1.16.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 typing-extensions-4.9.0 urllib3-2.2.1 werkzeug-3.0.1 wheel-0.42.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade --force-reinstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
