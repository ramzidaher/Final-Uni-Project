{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2a6aCsv8N7K",
        "outputId": "d6c08a14-8a95-4831-a5f1-90eca6e94920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAGuVw-K8pjz",
        "outputId": "dd907d5a-8fa3-48be-8bd8-b191d648e996"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library\n",
        "import pandas as pd\n",
        "\n",
        "# Define the data path\n",
        "data_path = '/content/drive/My Drive/Final-Uni-Project/Language-Identification-in-songs/Chara-Based-Model/Jupyter-Scripts/DataSets/Main_Full_Corrected_Updated_Lyrics_Training_Data (1).xlsx'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(data_path)\n",
        "\n",
        "# Display the first few rows to understand its structure\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNKvbwCi8aUg",
        "outputId": "c7edf6ad-fdca-4b11-f08e-a11a2fb7f40d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              lyrics language_label Artist\n",
            "0  I morgonens första ljus,\\ndär tystnaden bryts ...             SW    GPT\n",
            "1  В лучах заката мы встретились, не случайно,\\nН...             RU    GPT\n",
            "2  꿈속의 세계는 눈부시게 아름다워,\\n현실의 벽 너머로 손을 뻗어.\\n별빛 아래 속삭...             KO    GPT\n",
            "3  En el pueblo donde nací, las calles cuentan hi...             ES    GPT\n",
            "4  Под широким небом земли разных,\\nМы встречаемс...             RU    GPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset from the Excel file\n",
        "data = pd.read_excel(data_path)\n",
        "\n",
        "# Display the first few rows to understand its structure\n",
        "print(data.head())\n",
        "\n",
        "# Split the 'language_label' by commas, strip spaces, explode the resulting lists into separate rows, and then get the counts of each language\n",
        "language_counts = data['language_label'].str.split(',').explode().str.strip().value_counts()\n",
        "\n",
        "# Print the counts of each language\n",
        "print(language_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaRDoO_E8e9W",
        "outputId": "a556963e-855a-4780-ae0d-b8323d99f630"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              lyrics language_label Artist\n",
            "0  I morgonens första ljus,\\ndär tystnaden bryts ...             SW    GPT\n",
            "1  В лучах заката мы встретились, не случайно,\\nН...             RU    GPT\n",
            "2  꿈속의 세계는 눈부시게 아름다워,\\n현실의 벽 너머로 손을 뻗어.\\n별빛 아래 속삭...             KO    GPT\n",
            "3  En el pueblo donde nací, las calles cuentan hi...             ES    GPT\n",
            "4  Под широким небом земли разных,\\nМы встречаемс...             RU    GPT\n",
            "language_label\n",
            "AR    9\n",
            "KO    8\n",
            "RU    7\n",
            "SW    6\n",
            "PT    6\n",
            "DE    5\n",
            "HI    4\n",
            "ES    3\n",
            "IT    3\n",
            "FR    3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def normalize_text(texts):\n",
        "    normalized_texts = []\n",
        "    # Expanded set of punctuation to keep based on linguistic relevance\n",
        "    keep_punctuation = {\"'\", \"-\", \"’\", \":\", \",\", \".\", \"!\", \"?\", \";\"}\n",
        "\n",
        "    for text in texts:\n",
        "        try:\n",
        "            text = str(text).lower()\n",
        "            text = ' '.join(text.split())\n",
        "\n",
        "            # Retain letters, numbers, spaces, and specified punctuation, considering multilingual characters\n",
        "            text = ''.join(\n",
        "                char for char in text\n",
        "                if unicodedata.category(char)[0] in ('L', 'N', 'Z')  # Letter, number, or space\n",
        "                or char in keep_punctuation\n",
        "            )\n",
        "\n",
        "            # Remove standalone numbers that may not contribute significantly to language identification\n",
        "            text = re.sub(r'\\b\\d+\\b', ' ', text)\n",
        "\n",
        "            text = re.sub(r'[\\.\\,\\!\\?\\;\\:]+(?=[\\.\\,\\!\\?\\;\\:])', '', text)\n",
        "\n",
        "            # Ensure there are no extra spaces created by the replacements above\n",
        "            text = ' '.join(text.split())\n",
        "\n",
        "            normalized_texts.append(text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing text: {text} with error {e}\")\n",
        "            normalized_texts.append(\"\")  # Append an empty string to indicate an issue\n",
        "\n",
        "    return normalized_texts\n",
        "\n",
        "\n",
        "data['lyrics_normalized'] = normalize_text(data['lyrics'].tolist())\n",
        "\n",
        "print(data[['lyrics', 'lyrics_normalized']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMxHCg5T8iEp",
        "outputId": "5a62509c-4f93-483f-8d28-99b02c8bc86a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              lyrics  \\\n",
            "0  I morgonens första ljus,\\ndär tystnaden bryts ...   \n",
            "1  В лучах заката мы встретились, не случайно,\\nН...   \n",
            "2  꿈속의 세계는 눈부시게 아름다워,\\n현실의 벽 너머로 손을 뻗어.\\n별빛 아래 속삭...   \n",
            "3  En el pueblo donde nací, las calles cuentan hi...   \n",
            "4  Под широким небом земли разных,\\nМы встречаемс...   \n",
            "\n",
            "                                   lyrics_normalized  \n",
            "0  i morgonens första ljus, där tystnaden bryts a...  \n",
            "1  в лучах заката мы встретились, не случайно, на...  \n",
            "2  꿈속의 세계는 눈부시게 아름다워, 현실의 벽 너머로 손을 뻗어. 별빛 아래 속삭임,...  \n",
            "3  en el pueblo donde nací, las calles cuentan hi...  \n",
            "4  под широким небом земли разных, мы встречаемся...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all unique language codes from the 'language_label' column\n",
        "unique_languages = set()\n",
        "data['language_label'].apply(lambda labels: unique_languages.update(labels))\n",
        "\n",
        "# Sort and list the languages to have a consistent order\n",
        "unique_languages = sorted(list(unique_languages))\n",
        "\n",
        "# Create a mapping of languages to indices\n",
        "language_to_index = {lang: idx for idx, lang in enumerate(unique_languages)}\n",
        "\n",
        "print(f\"Unique languages in dataset: {unique_languages}\")\n",
        "print(f\"Language to index mapping: {language_to_index}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C2Tez9J8jyL",
        "outputId": "d271ae7d-7ebf-405c-f252-a35f98da637b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique languages in dataset: ['A', 'D', 'E', 'F', 'H', 'I', 'K', 'O', 'P', 'R', 'S', 'T', 'U', 'W']\n",
            "Language to index mapping: {'A': 0, 'D': 1, 'E': 2, 'F': 3, 'H': 4, 'I': 5, 'K': 6, 'O': 7, 'P': 8, 'R': 9, 'S': 10, 'T': 11, 'U': 12, 'W': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def labels_to_array(labels, language_to_index):\n",
        "    # Initialize an array of zeros\n",
        "    label_array = np.zeros(len(language_to_index), dtype=int)\n",
        "    # Set positions corresponding to the label to 1\n",
        "    for label in labels:\n",
        "        if label in language_to_index:  # Safety check\n",
        "            label_array[language_to_index[label]] = 1\n",
        "    return label_array\n",
        "\n",
        "# Apply the conversion to the entire dataset\n",
        "data['labels_array'] = data['language_label'].apply(lambda labels: labels_to_array(labels, language_to_index))\n",
        "\n",
        "# Check the first few entries to ensure correctness\n",
        "print(data[['language_label', 'labels_array']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjgQ2YvG8mHQ",
        "outputId": "979e161e-c6dd-4501-f05c-50e1e584729f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  language_label                                labels_array\n",
            "0             SW  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "1             RU  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
            "2             KO  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "3             ES  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "4             RU  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the features and labels for splitting\n",
        "X = data['lyrics_normalized'].values\n",
        "y = np.stack(data['labels_array'].values)\n",
        "\n",
        "# Split the data into training and testing sets, then split the training set further into training and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Validation set size: {X_val.shape[0]}\")\n",
        "print(f\"Testing set size: {X_test.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c-DfCCc8nYG",
        "outputId": "a1ffd760-fd03-4fe3-f3cd-38dfde221e91"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 32\n",
            "Validation set size: 11\n",
            "Testing set size: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "embedding_dim = 128\n",
        "output_dim = len(unique_languages)\n",
        "\n",
        "# Tokenization and Padding\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Define a custom F1 Score metric\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# Model Definition\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dense(output_dim, activation='sigmoid')  # Use 'sigmoid' for multi-label classification\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy', Precision(), Recall(), F1Score()])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Model Training\n",
        "history = model.fit(X_train_padded, y_train,\n",
        "                    epochs=100,\n",
        "                    validation_data=(X_val_padded, y_val))\n"
      ],
      "metadata": {
        "id": "eGvSMHgG8sJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cb03e6-a70f-4b2d-cc00-d4414c852384"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 14)                910       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1330318 (5.07 MB)\n",
            "Trainable params: 1330318 (5.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.0938 - precision_8: 0.1057 - recall_8: 0.3750 - f1_score: 0.1649"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  m.reset_state()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 8s 8s/step - loss: 0.6937 - accuracy: 0.0938 - precision_8: 0.1057 - recall_8: 0.3750 - f1_score: 0.1649 - val_loss: 0.6912 - val_accuracy: 0.0909 - val_precision_8: 0.1311 - val_recall_8: 0.3636 - val_f1_score: 0.1928\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6912 - accuracy: 0.1562 - precision_8: 0.1818 - recall_8: 0.4688 - f1_score: 0.2620 - val_loss: 0.6898 - val_accuracy: 0.0909 - val_precision_8: 0.1277 - val_recall_8: 0.2727 - val_f1_score: 0.1739\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.6886 - accuracy: 0.2812 - precision_8: 0.3103 - recall_8: 0.5625 - f1_score: 0.4000 - val_loss: 0.6883 - val_accuracy: 0.0909 - val_precision_8: 0.1429 - val_recall_8: 0.2273 - val_f1_score: 0.1754\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.6858 - accuracy: 0.3438 - precision_8: 0.4699 - recall_8: 0.6094 - f1_score: 0.5306 - val_loss: 0.6866 - val_accuracy: 0.1818 - val_precision_8: 0.1786 - val_recall_8: 0.2273 - val_f1_score: 0.2000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.6828 - accuracy: 0.4062 - precision_8: 0.6190 - recall_8: 0.6094 - f1_score: 0.6142 - val_loss: 0.6848 - val_accuracy: 0.0909 - val_precision_8: 0.2273 - val_recall_8: 0.2273 - val_f1_score: 0.2273\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6795 - accuracy: 0.4688 - precision_8: 0.7451 - recall_8: 0.5938 - f1_score: 0.6609 - val_loss: 0.6826 - val_accuracy: 0.2727 - val_precision_8: 0.2941 - val_recall_8: 0.2273 - val_f1_score: 0.2564\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.6758 - accuracy: 0.5000 - precision_8: 0.7872 - recall_8: 0.5781 - f1_score: 0.6667 - val_loss: 0.6801 - val_accuracy: 0.2727 - val_precision_8: 0.2667 - val_recall_8: 0.1818 - val_f1_score: 0.2162\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.6716 - accuracy: 0.4688 - precision_8: 0.7907 - recall_8: 0.5312 - f1_score: 0.6355 - val_loss: 0.6772 - val_accuracy: 0.2727 - val_precision_8: 0.2857 - val_recall_8: 0.1818 - val_f1_score: 0.2222\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 0.6667 - accuracy: 0.4688 - precision_8: 0.8250 - recall_8: 0.5156 - f1_score: 0.6346 - val_loss: 0.6738 - val_accuracy: 0.2727 - val_precision_8: 0.3333 - val_recall_8: 0.1818 - val_f1_score: 0.2353\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.6610 - accuracy: 0.4062 - precision_8: 0.8250 - recall_8: 0.5156 - f1_score: 0.6346 - val_loss: 0.6695 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 0.6541 - accuracy: 0.3438 - precision_8: 0.7941 - recall_8: 0.4219 - f1_score: 0.5510 - val_loss: 0.6642 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.6457 - accuracy: 0.3438 - precision_8: 0.7500 - recall_8: 0.3281 - f1_score: 0.4565 - val_loss: 0.6574 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.6352 - accuracy: 0.2188 - precision_8: 0.6154 - recall_8: 0.2500 - f1_score: 0.3556 - val_loss: 0.6484 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.6217 - accuracy: 0.0938 - precision_8: 0.5926 - recall_8: 0.2500 - f1_score: 0.3516 - val_loss: 0.6356 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 0.6035 - accuracy: 0.0938 - precision_8: 0.5714 - recall_8: 0.2500 - f1_score: 0.3478 - val_loss: 0.6162 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.5780 - accuracy: 0.0938 - precision_8: 0.4643 - recall_8: 0.2031 - f1_score: 0.2826 - val_loss: 0.5834 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.5408 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.5298 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.4924 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4849 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.4577 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4665 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.4427 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4579 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.4348 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4523 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.4288 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4473 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.4232 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4422 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4174 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4368 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.4113 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4312 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.4051 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4256 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.3989 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4201 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.3930 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4151 - val_accuracy: 0.2727 - val_precision_8: 0.3636 - val_recall_8: 0.1818 - val_f1_score: 0.2424\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.3876 - accuracy: 0.0938 - precision_8: 0.3750 - recall_8: 0.1875 - f1_score: 0.2500 - val_loss: 0.4107 - val_accuracy: 0.2727 - val_precision_8: 0.4444 - val_recall_8: 0.1818 - val_f1_score: 0.2581\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.3828 - accuracy: 0.0938 - precision_8: 0.4800 - recall_8: 0.1875 - f1_score: 0.2697 - val_loss: 0.4072 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.3789 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.4045 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.3757 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.4026 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.3730 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.4014 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.3704 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.4006 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.3678 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.4000 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.3646 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.3995 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.3609 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.3992 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.3569 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.3990 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.3529 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.3990 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3493 - accuracy: 0.0938 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.3985 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.3457 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.0312 - f1_score: 0.0606 - val_loss: 0.3970 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.3413 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.0938 - f1_score: 0.1714 - val_loss: 0.3945 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.3362 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1250 - f1_score: 0.2222 - val_loss: 0.3923 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.3315 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1250 - f1_score: 0.2222 - val_loss: 0.3916 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 0.3277 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1250 - f1_score: 0.2222 - val_loss: 0.3909 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.3241 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1719 - f1_score: 0.2933 - val_loss: 0.3879 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.3197 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3797 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.3153 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3674 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.3117 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3599 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.3080 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3557 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.3044 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3517 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.3012 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3485 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.2970 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3449 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3007 - accuracy: 0.0938 - precision_8: 0.9231 - recall_8: 0.1875 - f1_score: 0.3117 - val_loss: 0.3447 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.2924 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.2031 - f1_score: 0.3377 - val_loss: 0.3570 - val_accuracy: 0.1818 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.2906 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.2031 - f1_score: 0.3377 - val_loss: 0.3750 - val_accuracy: 0.0909 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.2880 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.2031 - f1_score: 0.3377 - val_loss: 0.3965 - val_accuracy: 0.0000e+00 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.2847 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.2031 - f1_score: 0.3377 - val_loss: 0.4026 - val_accuracy: 0.0000e+00 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.2807 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3981 - val_accuracy: 0.0000e+00 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.2763 - accuracy: 0.0938 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3874 - val_accuracy: 0.0000e+00 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.2719 - accuracy: 0.1875 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3719 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.2675 - accuracy: 0.1875 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3575 - val_accuracy: 0.2727 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.2632 - accuracy: 0.1875 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3475 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.0455 - val_f1_score: 0.0870\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.2590 - accuracy: 0.1562 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3400 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.2550 - accuracy: 0.2500 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3348 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.2512 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3313 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.2475 - accuracy: 0.2500 - precision_8: 1.0000 - recall_8: 0.1875 - f1_score: 0.3158 - val_loss: 0.3285 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.2438 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.2031 - f1_score: 0.3377 - val_loss: 0.3263 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.2400 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.2656 - f1_score: 0.4198 - val_loss: 0.3250 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.2362 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.2812 - f1_score: 0.4390 - val_loss: 0.3241 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.2320 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.2812 - f1_score: 0.4390 - val_loss: 0.3226 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.2276 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.3125 - f1_score: 0.4762 - val_loss: 0.3200 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2231 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.3750 - f1_score: 0.5455 - val_loss: 0.3172 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2187 - accuracy: 0.2188 - precision_8: 1.0000 - recall_8: 0.3750 - f1_score: 0.5455 - val_loss: 0.3154 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.2147 - accuracy: 0.1250 - precision_8: 1.0000 - recall_8: 0.3906 - f1_score: 0.5618 - val_loss: 0.3145 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.2108 - accuracy: 0.1250 - precision_8: 1.0000 - recall_8: 0.3906 - f1_score: 0.5618 - val_loss: 0.3138 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.0909 - val_f1_score: 0.1667\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2070 - accuracy: 0.1250 - precision_8: 1.0000 - recall_8: 0.3906 - f1_score: 0.5618 - val_loss: 0.3128 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.0909 - val_f1_score: 0.1667\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.2031 - accuracy: 0.1250 - precision_8: 1.0000 - recall_8: 0.4062 - f1_score: 0.5778 - val_loss: 0.3113 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.1992 - accuracy: 0.1250 - precision_8: 1.0000 - recall_8: 0.4375 - f1_score: 0.6087 - val_loss: 0.3086 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.1953 - accuracy: 0.1250 - precision_8: 1.0000 - recall_8: 0.5156 - f1_score: 0.6804 - val_loss: 0.3042 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1364 - val_f1_score: 0.2400\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.1913 - accuracy: 0.1250 - precision_8: 1.0000 - recall_8: 0.5469 - f1_score: 0.7071 - val_loss: 0.2954 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.1818 - val_f1_score: 0.3077\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.1875 - accuracy: 0.1562 - precision_8: 1.0000 - recall_8: 0.6094 - f1_score: 0.7573 - val_loss: 0.2895 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.2727 - val_f1_score: 0.4286\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.1838 - accuracy: 0.1875 - precision_8: 1.0000 - recall_8: 0.6719 - f1_score: 0.8037 - val_loss: 0.2873 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.2727 - val_f1_score: 0.4286\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.1801 - accuracy: 0.2188 - precision_8: 1.0000 - recall_8: 0.7812 - f1_score: 0.8772 - val_loss: 0.2901 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.2727 - val_f1_score: 0.4286\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.1768 - accuracy: 0.2812 - precision_8: 1.0000 - recall_8: 0.7812 - f1_score: 0.8772 - val_loss: 0.2801 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.2727 - val_f1_score: 0.4286\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.1733 - accuracy: 0.2500 - precision_8: 1.0000 - recall_8: 0.7812 - f1_score: 0.8772 - val_loss: 0.2762 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.2727 - val_f1_score: 0.4286\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.1701 - accuracy: 0.2500 - precision_8: 1.0000 - recall_8: 0.7656 - f1_score: 0.8673 - val_loss: 0.2716 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.3182 - val_f1_score: 0.4828\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.1665 - accuracy: 0.2500 - precision_8: 1.0000 - recall_8: 0.7969 - f1_score: 0.8870 - val_loss: 0.2669 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.3182 - val_f1_score: 0.4828\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.1631 - accuracy: 0.2500 - precision_8: 1.0000 - recall_8: 0.7969 - f1_score: 0.8870 - val_loss: 0.2638 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.3182 - val_f1_score: 0.4828\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.1599 - accuracy: 0.2500 - precision_8: 1.0000 - recall_8: 0.7969 - f1_score: 0.8870 - val_loss: 0.2614 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.3636 - val_f1_score: 0.5333\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1569 - accuracy: 0.2500 - precision_8: 0.9818 - recall_8: 0.8438 - f1_score: 0.9076 - val_loss: 0.2578 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.4091 - val_f1_score: 0.5806\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.1537 - accuracy: 0.2500 - precision_8: 0.9825 - recall_8: 0.8750 - f1_score: 0.9256 - val_loss: 0.2530 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.4091 - val_f1_score: 0.5806\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1506 - accuracy: 0.2500 - precision_8: 0.9825 - recall_8: 0.8750 - f1_score: 0.9256 - val_loss: 0.2478 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.4091 - val_f1_score: 0.5806\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.1475 - accuracy: 0.3125 - precision_8: 0.9825 - recall_8: 0.8750 - f1_score: 0.9256 - val_loss: 0.2446 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.3636 - val_f1_score: 0.5333\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.1489 - accuracy: 0.3125 - precision_8: 0.9818 - recall_8: 0.8438 - f1_score: 0.9076 - val_loss: 0.2748 - val_accuracy: 0.3636 - val_precision_8: 0.9000 - val_recall_8: 0.4091 - val_f1_score: 0.5625\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1435 - accuracy: 0.3125 - precision_8: 0.9825 - recall_8: 0.8750 - f1_score: 0.9256 - val_loss: 0.3663 - val_accuracy: 0.0909 - val_precision_8: 0.7778 - val_recall_8: 0.3182 - val_f1_score: 0.4516\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.1435 - accuracy: 0.3438 - precision_8: 0.9825 - recall_8: 0.8750 - f1_score: 0.9256 - val_loss: 0.3796 - val_accuracy: 0.0909 - val_precision_8: 0.7778 - val_recall_8: 0.3182 - val_f1_score: 0.4516\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.1444 - accuracy: 0.3438 - precision_8: 0.9825 - recall_8: 0.8750 - f1_score: 0.9256 - val_loss: 0.3697 - val_accuracy: 0.0909 - val_precision_8: 1.0000 - val_recall_8: 0.2727 - val_f1_score: 0.4286\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.1366 - accuracy: 0.3438 - precision_8: 0.9825 - recall_8: 0.8750 - f1_score: 0.9256 - val_loss: 0.3121 - val_accuracy: 0.2727 - val_precision_8: 1.0000 - val_recall_8: 0.2273 - val_f1_score: 0.3704\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.1334 - accuracy: 0.3438 - precision_8: 1.0000 - recall_8: 0.8750 - f1_score: 0.9333 - val_loss: 0.2782 - val_accuracy: 0.3636 - val_precision_8: 1.0000 - val_recall_8: 0.3636 - val_f1_score: 0.5333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics_names = ['loss', 'accuracy', 'precision', 'recall', 'f1_score']  # Adjust according to the metrics you have compiled your model with\n",
        "\n",
        "# Extract the metrics other than loss (starting from index 1 if index 0 is loss)\n",
        "results = eval_results[1:]  # This assumes loss is at index 0, adjust if your setup is different\n",
        "metrics_names = metrics_names[1:]  # Adjusting to skip 'loss'\n",
        "\n",
        "# Create a bar graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics_names, results, color=['blue', 'green', 'red', 'purple'])  # Colors as in your example\n",
        "for i, v in enumerate(results):\n",
        "    plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom')  # Add text on top of the bars\n",
        "\n",
        "plt.ylim(0, 1)  # Assuming the metric values are between 0 and 1\n",
        "plt.title('Evaluation Results')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "2gTT49nm8ukx",
        "outputId": "2ebc066c-5de7-4672-cb46-89fe9c2aa10b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}